{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d26aa4",
   "metadata": {},
   "source": [
    "# Databricks Workspace Inventory\n",
    "\n",
    "This notebook runs `workspace_inventory.py` from the repository. The notebook is designed to run on Databricks.\n",
    "\n",
    "Important: You do NOT need to provide a personal access token when running this notebook on Databricks clusters — the notebook will prefer the cluster's environment/authentication. If you do want to run against an external workspace or provide an explicit token, you may fill the Token widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e27f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets (Databricks notebook widgets).\n",
    "# Token is optional: leave empty to use notebook/cluster auth.\n",
    "try:\n",
    "    dbutils.widgets.text(\"workspace_url\", \"\", \"Workspace URL (optional)\")\n",
    "    dbutils.widgets.text(\"cluster_id\", \"auto\", \"Cluster ID (set to 'auto' for serverless or leave blank)\")\n",
    "    dbutils.widgets.text(\"profile\", \"DEFAULT\", \"Databricks CLI profile (optional)\")\n",
    "    dbutils.widgets.text(\"token\", \"\", \"Personal Access Token (optional; leave empty to use notebook auth)\")\n",
    "    dbutils.widgets.dropdown(\"output_format\", \"csv\", [\"csv\", \"parquet\", \"delta\"], \"Output format\")\n",
    "    dbutils.widgets.text(\"output_path\", \"/tmp/workspace_inventory\", \"Output path\")\n",
    "    print(\"Widgets created (Databricks notebook). Provide 'token' only if necessary.\")\n",
    "except NameError:\n",
    "    # Not running in Databricks notebook environment.\n",
    "    print(\"dbutils not found: not running in a Databricks notebook.\")\n",
    "    # Continue; later cells will handle missing dbutils by falling back to environment variables or direct CLI usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df43993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read widget values (works in Databricks). For non-Databricks runs, set environment variables or edit variables below.\n",
    "try:\n",
    "    workspace_url = dbutils.widgets.get(\"workspace_url\").strip()\n",
    "    cluster_id = dbutils.widgets.get(\"cluster_id\").strip()\n",
    "    profile = dbutils.widgets.get(\"profile\").strip()\n",
    "    token = dbutils.widgets.get(\"token\").strip()\n",
    "    output_format = dbutils.widgets.get(\"output_format\").strip()\n",
    "    output_path = dbutils.widgets.get(\"output_path\").strip()\n",
    "except NameError:\n",
    "    # Not a Databricks notebook; fall back to environment variables or defaults.\n",
    "    import os\n",
    "    workspace_url = os.environ.get(\"DATABRICKS_WORKSPACE_URL\", \"\")\n",
    "    cluster_id = os.environ.get(\"DATABRICKS_CLUSTER_ID\", \"\") or os.environ.get(\"DATABRICKS_SERVERLESS_COMPUTE_ID\", \"\")\n",
    "    profile = os.environ.get(\"DATABRICKS_CONFIG_PROFILE\", \"DEFAULT\")\n",
    "    token = os.environ.get(\"DATABRICKS_TOKEN\", \"\")\n",
    "    output_format = os.environ.get(\"OUTPUT_FORMAT\", \"csv\")\n",
    "    output_path = os.environ.get(\"OUTPUT_PATH\", \"/tmp/workspace_inventory\")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(\"  workspace_url:\", workspace_url if workspace_url else '(empty, will use profile or environment)')\n",
    "print(\"  cluster_id:\", cluster_id if cluster_id else '(empty)')\n",
    "print(\"  profile:\", profile)\n",
    "print(\"  token provided?:\", 'yes' if token else 'no')\n",
    "print(\"  output_format:\", output_format)\n",
    "print(\"  output_path:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86282fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (idempotent) and install requirements, then run the inventory script.\n",
    "import os, subprocess, sys, shlex\n",
    "repo_dir = '/tmp/dbx_workspace_inventory'\n",
    "if not os.path.exists(repo_dir):\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/LaurentPRAT-DB/dbx_workspace_inventory.git', repo_dir], check=True)\n",
    "else:\n",
    "    print('Repository already present at', repo_dir)\n",
    "\n",
    "# Install requirements into the notebook driver (Databricks will isolate jobs, but installing here helps when running interactively)\n",
    "req_file = os.path.join(repo_dir, 'requirements.txt')\n",
    "if os.path.exists(req_file):\n",
    "    print('Installing requirements from', req_file)\n",
    "    try:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', req_file], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('Warning: pip install returned non-zero exit code:', e)\n",
    "else:\n",
    "    print('No requirements.txt found; continuing')\n",
    "\n",
    "# Build command to run the script. Token is optional — include it only when provided.\n",
    "cmd = [sys.executable, 'workspace_inventory.py']\n",
    "# Working directory for running the script\n",
    "cwd = repo_dir\n",
    "\n",
    "if workspace_url:\n",
    "    cmd.extend(['--workspace-url', workspace_url])\n",
    "if profile:\n",
    "    cmd.extend(['--profile', profile])\n",
    "if cluster_id:\n",
    "    # Provide cluster_id only if not empty\n",
    "    cmd.extend(['--cluster-id', cluster_id])\n",
    "# Include token only when explicitly provided.\n",
    "if token:\n",
    "    cmd.extend(['--token', token])\n",
    "# Output options\n",
    "if output_format:\n",
    "    cmd.extend(['--format', output_format])\n",
    "if output_path:\n",
    "    cmd.extend(['--output', output_path])\n",
    "\n",
    "print('Running command:')\n",
    "print(' '.join(shlex.quote(p) for p in cmd))\n",
    "\n",
    "# Execute and stream output live\n",
    "proc = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "for line in proc.stdout:\n",
    "    print(line, end='')\n",
    "ret = proc.wait()\n",
    "print('\n",
    "Process exited with code', ret)\n",
    "# Diagnostic: print cluster Python and Spark versions (useful for Spark Connect alignment)\n",
    "import sys\n",
    "import platform\n",
    "try:\n",
    "    py_exec = sys.executable\n",
    "    py_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "    print(\"Python executable:\", py_exec)\n",
    "    print(\"Python version:\", py_version)\n",
    "    # Try to obtain Spark version from existing session or create one\n",
    "    try:\n",
    "        spark_version = spark.version  # notebook usually exposes `spark`\n",
    "    except NameError:\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        spark_version = spark.version\n",
    "    print(\"Spark version:\", spark_version)\n",
    "    # Show platform details for more precise matching\n",
    "    print(\"Platform:\", platform.platform())\n",
    "except Exception as _e:\n",
    "    print(\"Could not determine Python/Spark versions:\", str(_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e81afd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- When run on Databricks, the notebook will prefer notebook/cluster authentication and **you don't need to provide a personal access token**.\n",
    "- If you need to run against a remote workspace from your local environment, provide a token in the Token widget (or set `DATABRICKS_TOKEN` environment variable).\n",
    "- The notebook installs `requirements.txt` into the driver environment; cluster/executor package setup may differ depending on your Databricks configuration."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
